{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get device information\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Extracting data and feature\n",
    "\n",
    "# Normalize Audio data\n",
    "def Amplitude_Normalization(y):\n",
    "    audio_data = []\n",
    "    max_signal = max(y); min_signal = min(y)\n",
    "    for i, signal in enumerate(y):\n",
    "        norm_signal = (signal - min_signal)/(max_signal - min_signal)\n",
    "        audio_data.append(norm_signal)\n",
    "    audio_data = np.array(audio_data)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "# Raw data\n",
    "def _Extract_audio(wav_dir, file_df):\n",
    "    audio_data = []\n",
    "    for filename in file_df['filename']:\n",
    "        path = os.path.join(wav_dir, filename)\n",
    "        y, sr = librosa.load(path, mono=False)\n",
    "        audio_data.append(y[0].T)\n",
    "\n",
    "    return audio_data\n",
    "\n",
    "# Get Pitches from audio\n",
    "def _audio_pitch(wav_dir, file_df):\n",
    "    pitches = []\n",
    "    for filename in file_df['filename']:\n",
    "        path = os.path.join(wav_dir, filename)\n",
    "        y, sr = librosa.load(path, mono=False)\n",
    "        try:\n",
    "            pitch, _ = librosa.piptrack(y=y[0], sr=sr)\n",
    "        except:\n",
    "            pitch, _ = librosa.piptrack(y=y, sr=sr)\n",
    "        pitch = pitch.mean(axis=0)\n",
    "        pitches.append(pitch)\n",
    "        \n",
    "    return pitches\n",
    "\n",
    "# Get Chroma Features from audio\n",
    "def _audio_chroma(wav_dir, file_df):\n",
    "    chromas = []\n",
    "    for filename in file_df['filename']:\n",
    "        path = os.path.join(wav_dir, filename)\n",
    "        y, sr = librosa.load(path, mono=False)\n",
    "        chroma = librosa.feature.chroma_stft(y=y[0], sr=sr)\n",
    "        chromas.append(chroma.T)\n",
    "\n",
    "    return chromas\n",
    "\n",
    "# Get Mel-Frequency Cepstral Coefficient from audio\n",
    "def _audio_MFCC(wav_dir, file_df):\n",
    "    audio_data = []\n",
    "    for filename in file_df['filename']:\n",
    "        path = os.path.join(wav_dir, filename)\n",
    "        y, sr = librosa.load(path, mono=False)\n",
    "        mfcc = librosa.feature.mfcc(y=y[0], sr=sr, n_mfcc=40)\n",
    "        audio_data.append(mfcc.T)  \n",
    "\n",
    "    return audio_data\n",
    "\n",
    "# Get Zero Crossing Rate from audio\n",
    "def _audio_ZCR(wav_dir, file_df):\n",
    "    zcrs = []\n",
    "    for filename in file_df['filename']:\n",
    "        path = os.path.join(wav_dir, filename)\n",
    "        y, sr = librosa.load(path, mono=False)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y[0])\n",
    "        zcrs.append(zcr.T)\n",
    "\n",
    "    return zcrs\n",
    "\n",
    "# Get RMS Energy from audio\n",
    "def _audio_energy(wav_dir, file_df):\n",
    "    energies = []\n",
    "    for filename in file_df['filename']:\n",
    "        path = os.path.join(wav_dir, filename)\n",
    "        y, sr = librosa.load(path, mono=False)\n",
    "        energy = librosa.feature.rms(y=y[0])\n",
    "        energies.append(energy.T)\n",
    "\n",
    "    return energies\n",
    "\n",
    "# Normalize labels\n",
    "def normalize_CQ(df):\n",
    "    list_CQ = []\n",
    "    for i, y in enumerate(df):\n",
    "        y_min = min(df); y_max = max(df)\n",
    "        n_CQ = (y - y_min) / (y_max - y_min)\n",
    "        list_CQ.append(n_CQ)\n",
    "        \n",
    "    return list_CQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset -> [batch, seq_length, input_size]\n",
    "class wavDataset(Dataset):\n",
    "    def __init__(self, wav_dir, csv_path, feature='Raw',subset=None):\n",
    "        # Load dataframe\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Extract Audio data\n",
    "        if(feature == 'Raw'):\n",
    "            self.audio = _Extract_audio(wav_dir, df)\n",
    "        elif(feature == 'Pitch'):\n",
    "            self.audio = _audio_pitch(wav_dir, df)\n",
    "        elif(feature == 'MFCC'):\n",
    "            self.audio = _audio_MFCC(wav_dir, df)\n",
    "        elif(feature == 'Chroma'):\n",
    "            self.audio = _audio_chroma(wav_dir, df)\n",
    "        elif(feature == 'ZCR'):\n",
    "            self.audio = _audio_ZCR(wav_dir, df)\n",
    "        elif(feature == \"Energy\"):\n",
    "            self.audio = _audio_energy(wav_dir, df)\n",
    "        # Target data\n",
    "        self.CQ = df['CQ']\n",
    "\n",
    "        # Split dataset for train/test\n",
    "        split_idx1 = 193\n",
    "        split_idx2 = 215\n",
    "        if subset == 0: # Return Train dataset\n",
    "            self.data = self.audio[:split_idx1]\n",
    "            self.labels = self.CQ[:split_idx1].reset_index(drop=True)\n",
    "        elif subset == 1: # Return Validation dataset\n",
    "            self.data = self.audio[split_idx1:split_idx2]\n",
    "            self.labels = self.CQ[split_idx1:split_idx2].reset_index(drop=True)\n",
    "        elif subset == 2: # Return Test dataset\n",
    "            self.data = self.audio[split_idx2:]\n",
    "            self.labels = self.CQ[split_idx2:].reset_index(drop=True)\n",
    "        else: # Return Complete dataset\n",
    "            self.data = self.audio\n",
    "            self.labels = self.CQ\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_tensor = torch.from_numpy(self.data[index]).float()\n",
    "        audio_tensor = audio_tensor.unsqueeze(1)\n",
    "        label_tensor = torch.tensor(self.labels[index]).float()\n",
    "\n",
    "        return audio_tensor, label_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for padding sequence\n",
    "def my_collate_fn(batch):\n",
    "    inputs, outputs = zip(*batch)\n",
    "    padded_inputs = pad_sequence(inputs,\n",
    "                                 batch_first=True,\n",
    "                                 padding_value=0)\n",
    "    \n",
    "    outputs = torch.stack(outputs)\n",
    "\n",
    "    return padded_inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ft, batch):\n",
    "    train_dir='/home/hyeonbin/hbb_work/EGG_data/train'\n",
    "    test_dir='/home/hyeonbin/hbb_work/EGG_data/test'\n",
    "    csv_train='/home/hyeonbin/hbb_work/wavtxt/wav_CQ_train.csv'\n",
    "    csv_test='/home/hyeonbin/hbb_work/wavtxt/wav_CQ_test.csv'\n",
    "\n",
    "    train_dataset = wavDataset(wav_dir=train_dir,\n",
    "                                csv_path=csv_train,\n",
    "                                feature=ft) # Train data\n",
    "\n",
    "    test_dataset = wavDataset(wav_dir=test_dir,\n",
    "                                csv_path=csv_test,\n",
    "                                feature=ft) # Test data\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch,\n",
    "                            shuffle=True)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch,\n",
    "                            shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def mean_absolute_error(outputs, targets):\n",
    "    return torch.mean(torch.abs(outputs - targets))\n",
    "\n",
    "def root_mean_squared_error(outputs, targets):\n",
    "    return torch.sqrt(torch.mean((outputs - targets) ** 2))\n",
    "\n",
    "def MAPELoss(outputs, targets):\n",
    "    diff = torch.abs((outputs - targets) / (targets)) * 10\n",
    "    loss = torch.mean(diff)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(y_true, y_pred, title):\n",
    "    TimesNewRoman = fm.FontProperties(fname=\"/home/hyeonbin/anaconda3/fonts/Times_New_Roman.ttf\")\n",
    "    TimesNewRomanBold = fm.FontProperties(fname=\"/home/hyeonbin/anaconda3/fonts/Times_New_Roman_Bold.ttf\")\n",
    "\n",
    "    lim = [y_true.min(), y_true.max(), y_pred.min(), y_pred.max()]\n",
    "    plt.figure((5, 5))\n",
    "    x = np.arange(lim.min(), lim.max()+0.1, 0.1)\n",
    "    y = x\n",
    "    \n",
    "    titledict = {'fontsize': 20,\n",
    "                 'style': 'normal', # 'oblique' 'italic'\n",
    "                 'fontweight': 'normal'} # 'bold', 'heavy', 'light', 'ultrabold', 'ultralight\n",
    "\n",
    "    labeldict = {'fontsize': 15,\n",
    "                 'style': 'normal', # 'oblique' 'italic'\n",
    "                 'fontweight': 'normal'} # 'bold', 'heavy', 'light', 'ultrabold', 'ultralight'\n",
    "    \n",
    "    x_label = \"Exact data\"; y_label = \"Predict data\"\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(y_true, y_pred, s=10, c='black')\n",
    "    plt.plot(x, y, linestyle='-.', color='red')\n",
    "    plt.xlim(lim.min(), lim.max())\n",
    "    plt.ylim(lim.min(), lim.max())\n",
    "    plt.title(title, fontproperties=TimesNewRomanBold, **titledict)\n",
    "    plt.xlabel(f'{x_label:>60}', fontproperties=TimesNewRoman, **labeldict)\n",
    "    plt.ylabel(f'{y_label:>60}', fontproperties=TimesNewRoman, **labeldict)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def train_model(model, num_epochs, criterion, optimizer, batch, feature, tag):\n",
    "    # Record Losses to txt files\n",
    "    f_train = open(f\"/home/hyeonbin/hbb_work/Model_eval/{feature}/{tag}_train.txt\", \"w+\")\n",
    "    f_test = open(f\"/home/hyeonbin/hbb_work/Model_eval/{feature}/{tag}_test.txt\", \"w+\")\n",
    "\n",
    "    train_loader, test_loader = load_data(feature, batch)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Training Mode\n",
    "        total_train_loss = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)            \n",
    "            total_train_loss += loss.item() * inputs.size(0)\n",
    "            total_train_samples += inputs.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        average_train_loss = total_train_loss / total_train_samples\n",
    "        # writer.add_scalar(f\"{feature}_{tag}/Loss/Train\", average_train_loss, epoch)\n",
    "        f_train.write(f\"{average_train_loss}\\n\")\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {average_train_loss:.6f}')\n",
    "\n",
    "        model.eval() # Inference Mode\n",
    "        total_test_loss = 0\n",
    "        total_test_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, targets in test_loader: # Test\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_test_loss += loss.item() * inputs.size(0)\n",
    "                total_test_samples += inputs.size(0)\n",
    "\n",
    "            average_test_loss = total_test_loss / total_test_samples\n",
    "            # writer.add_scalar(f\"{feature}_{tag}/Loss/Test\", average_test_loss, epoch)\n",
    "            f_test.write(f\"{average_test_loss}\\n\")\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {average_test_loss:.6f}')\n",
    "    \n",
    "    # Epoch End\n",
    "    model.eval() # Inference Mode\n",
    "    y_exact_test = []\n",
    "    y_pred_test = []\n",
    "    y_exact_train = []\n",
    "    y_pred_train = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader: # Test\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            for i in targets.cpu():\n",
    "                y_exact_train.append(i)\n",
    "            for i in outputs.cpu():\n",
    "                y_pred_train.append(i)\n",
    "\n",
    "        for inputs, targets in train_loader: # Train\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            for i in targets.cpu():\n",
    "                y_exact_train.append(i)\n",
    "            for i in outputs.cpu():\n",
    "                y_pred_train.append(i)\n",
    "    \n",
    "    plot_performance('Train', y_exact_train, y_pred_train)\n",
    "    plot_performance('Test', y_exact_test, y_pred_test)\n",
    "\n",
    "    # writer.flush()\n",
    "    f_train.close\n",
    "    f_test.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer_model(model, num_epochs, criterion, optimizer, batch, feature, tag):\n",
    "    # Record Losses to txt files\n",
    "    f_train = open(f\"/home/hyeonbin/hbb_work/Model_eval/{feature}/{tag}_train.txt\", \"w+\")\n",
    "    f_test = open(f\"/home/hyeonbin/hbb_work/Model_eval/{feature}/{tag}_test.txt\", \"w+\")\n",
    "\n",
    "    train_loader, test_loader = load_data(feature, batch)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Training Mode\n",
    "        total_train_loss = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs = inputs.squeeze(2).to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)            \n",
    "            total_train_loss += loss.item() * inputs.size(0)\n",
    "            total_train_samples += inputs.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        average_train_loss = total_train_loss / total_train_samples\n",
    "        # writer.add_scalar(f\"{feature}_{tag}/Loss/Train\", average_train_loss, epoch)\n",
    "        f_train.write(f\"{average_train_loss}\\n\")\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {average_train_loss:.6f}')\n",
    "\n",
    "        model.eval() # Inference Mode\n",
    "        total_test_loss = 0\n",
    "        total_test_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, targets in test_loader: # Test\n",
    "                inputs = inputs.squeeze(2).to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_test_loss += loss.item() * inputs.size(0)\n",
    "                total_test_samples += inputs.size(0)\n",
    "\n",
    "            average_test_loss = total_test_loss / total_test_samples\n",
    "            # writer.add_scalar(f\"{feature}_{tag}/Loss/Test\", average_test_loss, epoch)\n",
    "            f_test.write(f\"{average_test_loss}\\n\")\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Test Loss: {average_test_loss:.6f}')\n",
    "    \n",
    "    # Epoch End\n",
    "    model.eval() # Inference Mode\n",
    "    y_exact_test = []\n",
    "    y_pred_test = []\n",
    "    y_exact_train = []\n",
    "    y_pred_train = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in train_loader: # Train\n",
    "            inputs = inputs.squeeze(2).to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            for i in targets.cpu():\n",
    "                y_exact_train.append(i.item())\n",
    "            for i in outputs.cpu():\n",
    "                y_pred_train.append(i.item())\n",
    "\n",
    "        for inputs, targets in test_loader: # Test\n",
    "            inputs = inputs.squeeze(2).to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            for i in targets.cpu():\n",
    "                y_exact_test.append(i.item())\n",
    "            for i in outputs.cpu():\n",
    "                y_pred_test.append(i.item())\n",
    "\n",
    "    plot_performance('Train', y_exact_train, y_pred_train)\n",
    "    plot_performance('Test', y_exact_test, y_pred_test)\n",
    "\n",
    "    # writer.flush()\n",
    "    f_train.close\n",
    "    f_test.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(model_GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size,\n",
    "                          hidden_size,\n",
    "                          num_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU 1Layer Bidirectional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_BiGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(model_BiGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size,\n",
    "                          hidden_size,\n",
    "                          num_layers,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True,\n",
    "                          dropout=0.3)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D + GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_GRU(nn.Module):\n",
    "    def __init__(self, input_size, num_channels, gru_hidden_size, gru_num_layers, output_size):\n",
    "        super(CNN_GRU, self).__init__()\n",
    "\n",
    "        # Conv1D Layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size,\n",
    "                               out_channels=num_channels,\n",
    "                               kernel_size=3, \n",
    "                               padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=num_channels,\n",
    "                               out_channels=num_channels*2,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "\n",
    "        # GRU Layers\n",
    "        self.gru = nn.GRU(input_size=num_channels*2,\n",
    "                        hidden_size=gru_hidden_size,\n",
    "                          num_layers=gru_num_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=0.3)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(gru_hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv1D Layers\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Convert result of Conv1D fit to inputs of GRU\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        # GRU Layer\n",
    "        out, _ = self.gru(x)\n",
    "\n",
    "        # Use only the output of the last time step\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model=d_model,\n",
    "                                          nhead=nhead,\n",
    "                                          num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=0.1)\n",
    "        self.fc_in = nn.Linear(input_dim, d_model)\n",
    "        self.fc_out = nn.Linear(d_model, 1)  # Target: Scalar\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.fc_in(src)  # 입력 차원을 d_model로 변환\n",
    "        src = src.permute(1, 0, 2)  # Transformer 기대 입력 형태로 차원 순서 변경: (S, N, E)\n",
    "        output = self.transformer.encoder(src)  # 인코더 한 번만 호출\n",
    "        output = output.permute(1, 0, 2)  # 원래 배치 차원 순서로 되돌림: (N, S, E)\n",
    "        output = self.fc_out(output[:, -1, :])  # 마지막 시퀀스 요소의 출력만 사용\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/usr/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_XGB(max_depth, eta, seed, rounds, feature, batch=1):\n",
    "    train_loader, test_loader = load_data(feature, batch)\n",
    "\n",
    "    # Load Training data\n",
    "    for inputs, targets in train_loader:\n",
    "        X_train = inputs.numpy()\n",
    "        Y_train = targets.numpy()\n",
    "        break\n",
    "\n",
    "    # Load Test data\n",
    "    for inputs, targets in test_loader:\n",
    "        X_test = inputs.numpy()\n",
    "        Y_test = targets.numpy()\n",
    "        break\n",
    "\n",
    "    # Generate DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=Y_test)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': max_depth,\n",
    "        'eta': eta,\n",
    "        'eval_metric': 'rmse',\n",
    "        'seed': seed\n",
    "    }\n",
    "\n",
    "    evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "    bst = xgb.train(params, dtrain, rounds, evals=evals, early_stopping_rounds=10)\n",
    "\n",
    "    y_pred_train = bst.predict(dtrain)\n",
    "    y_exact_train = dtrain.get_label()\n",
    "\n",
    "    y_pred_test = bst.predict(dtest)\n",
    "    y_exact_test = dtest.ger_label()\n",
    "\n",
    "    plot_performance('Train', y_exact_train, y_pred_train)\n",
    "    plot_performance('Test', y_exact_test, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
